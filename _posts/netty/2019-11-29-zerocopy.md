---
layout: post
title:  深入剖析零拷贝机制
category: netty
tags: [netty]
excerpt: netty
---

## 前言
  零拷贝（Zero-copy）技术指在计算机执行操作时，CPU 不需要先将数据从一个内存区域复制到另一个内存区域，从而可以减少上下文切换以及 CPU 的拷贝时间。它的作用是在数据报从网络设备到用户程序空间传递的过程中，减少数据拷贝次数，减少系统调用，实现 CPU 的零参与，彻底消除 CPU 在这方面的负载。实现零拷贝用到的最主要技术是 DMA 数据传输技术和内存区域映射技术。

零拷贝机制可以减少数据在内核缓冲区和用户进程缓冲区之间反复的 I/O 拷贝操作。
零拷贝机制可以减少用户进程地址空间和内核地址空间之间因为上下文切换而带来的 CPU 开销。

特别申明：本文所说的环境都是基于Unix和linux。


## 业务场景
从一个文件中读出大量的数据并将这些数据传到另一台服务器上，有什么高效的方式实现？

## 知识铺垫(摘自互联网)
### 1.用户空间 / 内核空间
现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。
操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操作系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。

### 2.进程切换
为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的，并且进程切换是非常耗费资源的。

### 3.进程阻塞
正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得了CPU资源），才可能将其转为阻塞状态。当进程进入阻塞状态，是不占用CPU资源的。
文件描述符 文件描述符（File
descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。
文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。

### 4.缓存I/O
缓存I/O又称为标准I/O，大多数文件系统的默认I/O操作都是缓存I/O。在Linux的缓存I/O机制中，操作系统会将I/O的数据缓存在文件系统的页缓存中，即数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。



## 传统IO方式
传统的IO实现：通过file.read()和
socket.send()两个方法配合实现client将硬盘上的文件发送到server端，交互图如下：

![](/assets/images/2019/zerocopy/io.png)

1、应用程序调用
read()方法，这里会涉及到第1次上下文切换（用户态->内核态），底层采用DMA（direct
memory access）读取磁盘的文件，并把内容copy到内核地址空间的Read
Buffer(读取缓存区)。

2、由于应用程序无法访问内核地址空间的数据，如果应用程序要操作这些数据，就得把这些内容从内核的Read
Buffer(读取缓冲区) copy 到Application Buffer(用户缓冲区)。 read()方法
调用的返回引发第2次上下文切换（内核态->用户态），现在数据已经被拷贝到了用户地址空间缓冲区，如果有需要，可以操作修改这些内容。

3、我们最终目的是把这个文件内容通过Socket传到另一个服务中，调用Socket的
send()方法，涉及到第3次上下文切换（用户态->内核态），同时，文件内容被进行第三次拷贝，数据从Application
Buffer（用户缓冲区）拷贝到Socket Buffer(内核的socket缓冲区)。

4、send()调用返回，引发第4次上下文切换，同时进行第四次拷贝，DMA把数据从Socket
Buffer（目标Socket相关的缓存区）传到NIC Buffer（协议引擎）进行发送。

整个流程中，Copy1和Copy4是DMA
copy，并不会消耗CPU，只有Copy2和Copy3的拷贝需要CPU参与

上面方法是传统IO的实现过程，里面牵涉到4次上下文的切换和4次拷贝（2次需要cpu参与的拷贝，2次DMA
copy)。

![](/assets/images/2019/zerocopy/io2.png)

1. 上下文切换：当用户程序向内核发起系统调用时，CPU 将用户进程从用户态切换到内核态；当系统调用返回时，CPU 将用户进程从内核态切换回用户态。
2. CPU拷贝：由 CPU 直接处理数据的传送，数据拷贝时会一直占用 CPU 的资源。
3. DMA拷贝：由 CPU 向DMA磁盘控制器下达指令，让 DMA 控制器来处理数据的传送，数据传送完毕再把信息反馈给 CPU，从而减轻了 CPU 资源的占有率。


![](/assets/images/2019/zerocopy/io2.png)

1. 用户进程向 CPU 发起 read 系统调用读取数据，由用户态切换为内核态，然后一直阻塞等待数据的返回。
2. CPU 在接收到指令以后对磁盘发起 I/O 请求，将磁盘数据先放入磁盘控制器缓冲区。
3. 数据准备完成以后，磁盘向 CPU 发起 I/O 中断。
4. CPU 收到 I/O 中断以后将磁盘缓冲区中的数据拷贝到内核缓冲区，然后再从内核缓冲区拷贝到用户缓冲区。
5. 用户进程由内核态切换回用户态，解除阻塞状态，然后等待 CPU 的下一个执行时间钟。



## NIO方式
NIO实现方法可以用transferTo()替代file.read()和 socket.send()，交互原理图如下：

![](/assets/images/2019/zerocopy/zero-sendfile1.png)

从图可以看到，上下文切换的次数从四次减少到了两次，拷贝次数从四次减少到三次(DMA
copy 2次，CPU copy 1次)，尽管改善了很多，但还是有1次CPU
copy，所以达不到完全的零拷贝，那么有什么更好的黑科技可以实现真正意义上的 Zero
Copy呢？想得到答案，我们先来看看FileChannel#transferTo()方法的源码，看看源码中有没有什么蛛丝马迹


![](/assets/images/2019/zerocopy/zero-sendfile2.png)

1. 用户进程通过 sendfile() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）。
2. CPU 利用 DMA 控制器将数据从主存或硬盘拷贝到内核空间（kernel space）的读缓冲区（read buffer）。
3. CPU 将读缓冲区（read buffer）中的数据拷贝到的网络缓冲区（socket buffer）。
4. CPU 利用 DMA 控制器将数据从网络缓冲区（socket buffer）拷贝到网卡进行数据传输。
5. 上下文从内核态（kernel space）切换回用户态（user space），sendfile 系统调用执行返回。
6. sendfile 存在的问题是用户程序不能对数据进行修改，而只是单纯地完成了一次数据传输过程。

transferTo()源码内容
```java

// 接口定义
package java.nio.channels;

public abstract class FileChannel
    extends AbstractInterruptibleChannel
    implements SeekableByteChannel, GatheringByteChannel, ScatteringByteChannel
{
    /**
     * Transfers bytes from this channel's file to the given writable byte
     * channel.
     *
     * <p> An attempt is made to read up to <tt>count</tt> bytes starting at
     * the given <tt>position</tt> in this channel's file and write them to the
     * target channel.  An invocation of this method may or may not transfer
     * all of the requested bytes; whether or not it does so depends upon the
     * natures and states of the channels.  Fewer than the requested number of
     * bytes are transferred if this channel's file contains fewer than
     * <tt>count</tt> bytes starting at the given <tt>position</tt>, or if the
     * target channel is non-blocking and it has fewer than <tt>count</tt>
     * bytes free in its output buffer.
     *
     * <p> This method does not modify this channel's position.  If the given
     * position is greater than the file's current size then no bytes are
     * transferred.  If the target channel has a position then bytes are
     * written starting at that position and then the position is incremented
     * by the number of bytes written.
     *
     * <p> This method is potentially much more efficient than a simple loop
     * that reads from this channel and writes to the target channel.  Many
     * operating systems can transfer bytes directly from the filesystem cache
     * to the target channel without actually copying them.  </p>
     *
     * @param  position
     *         The position within the file at which the transfer is to begin;
     *         must be non-negative
     *
     * @param  count
     *         The maximum number of bytes to be transferred; must be
     *         non-negative
     *
     * @param  target
     *         The target channel
     *
     * @return  The number of bytes, possibly zero,
     *          that were actually transferred
     *
     * @throws IllegalArgumentException
     *         If the preconditions on the parameters do not hold
     *
     * @throws  NonReadableChannelException
     *          If this channel was not opened for reading
     *
     * @throws  NonWritableChannelException
     *          If the target channel was not opened for writing
     *
     * @throws  ClosedChannelException
     *          If either this channel or the target channel is closed
     *
     * @throws  AsynchronousCloseException
     *          If another thread closes either channel
     *          while the transfer is in progress
     *
     * @throws  ClosedByInterruptException
     *          If another thread interrupts the current thread while the
     *          transfer is in progress, thereby closing both channels and
     *          setting the current thread's interrupt status
     *
     * @throws  IOException
     *          If some other I/O error occurs
     */
    public abstract long transferTo(long position, long count,
                                    WritableByteChannel target)
        throws IOException;
    
    }
```

```java
// 接口实现
package sun.nio.ch;
public class FileChannelImpl extends FileChannel {
    public long transferTo(long var1, long var3, WritableByteChannel var5) throws IOException {
        this.ensureOpen();
        if (!var5.isOpen()) {
            throw new ClosedChannelException();
        } else if (!this.readable) {
            throw new NonReadableChannelException();
        } else if (var5 instanceof FileChannelImpl && !((FileChannelImpl)var5).writable) {
            throw new NonWritableChannelException();
        } else if (var1 >= 0L && var3 >= 0L) {
            long var6 = this.size();
            if (var1 > var6) {
                return 0L;
            } else {
                int var8 = (int)Math.min(var3, 2147483647L);
                if (var6 - var1 < (long)var8) {
                    var8 = (int)(var6 - var1);
                }

                long var9;
                if ((var9 = this.transferToDirectly(var1, var8, var5)) >= 0L) {
                    return var9;
                } else {
                    return (var9 = this.transferToTrustedChannel(var1, (long)var8, var5)) >= 0L ? var9 : this.transferToArbitraryChannel(var1, var8, var5);
                }
            }
        } else {
            throw new IllegalArgumentException();
        }
    }
}
```  
通过 FileChannelImpl的源码可以看到，该类位于sun.nio.ch包下面，代码是反编译得到的，所以看到的变量命名之类的很奇怪，在 UNIX 和各种 Linux 系统中，此调用被传递到 sendfile() 系统调用中，最终实现将数据从一个文件描述符传输到了另一个文件描述符。

google看下操作系统级别sendfile()方法的描述和实现 
```
       SYNOPSIS         top
       #include <sys/sendfile.h>

       ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);
       DESCRIPTION         top
       sendfile() copies data between one file descriptor and another.
       Because this copying is done within the kernel, sendfile() is more
       efficient than the combination of read(2) and write(2), which would
       require transferring data to and from user space.
 
翻译：sendfile()在一个文件描述符和另一个文件描述符之间复制数据。因为复制是在内核中完成的，所以sendfile()的功能更多
效率比读(2)和写(2)的组合，这将需要在用户空间之间传输数据。
```

sendfile()方法C语言实现源码
```java
// 文件地址
https://code.woboq.org/userspace/glibc/sysdeps/unix/sysv/linux/generic/wordsize-32/sendfile.c.html
Browse the source code of glibc/sysdeps/unix/sysv/linux/generic/wordsize-32/sendfile.c

/* Copyright (C) 2011-2019 Free Software Foundation, Inc.
   This file is part of the GNU C Library.
   Contributed by Chris Metcalf <cmetcalf@tilera.com>, 2011.
   The GNU C Library is free software; you can redistribute it and/or
   modify it under the terms of the GNU Lesser General Public
   License as published by the Free Software Foundation; either
   version 2.1 of the License, or (at your option) any later version.
   The GNU C Library is distributed in the hope that it will be useful,
   but WITHOUT ANY WARRANTY; without even the implied warranty of
   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
   Lesser General Public License for more details.
   You should have received a copy of the GNU Lesser General Public
   License along with the GNU C Library.  If not, see
   <http://www.gnu.org/licenses/>.  */

#include <sys/sendfile.h>
#include <errno.h>
/* Send COUNT bytes from file associated with IN_FD starting at OFFSET to
   descriptor OUT_FD.  */
ssize_t
sendfile (int out_fd, int in_fd, off_t *offset, size_t count)
{
  __off64_t off64;
  int rc;
  if (offset != NULL)
    {
      if (*offset < 0 || (off_t) (*offset + count) < 0)
        {
          __set_errno (EINVAL);
          return -1;
        }
      off64 = *offset;
    }
  rc = INLINE_SYSCALL (sendfile64, 4, out_fd, in_fd,
                       offset ? &off64 : NULL, count);
  if (offset)
    *offset = off64;
  return rc;
}
```

特别注意，transferTo()方法源码注释说明中有这样一段话：

```
     * <p> This method is potentially much more efficient than a simple loop
     * that reads from this channel and writes to the target channel.  Many
     * operating systems can transfer bytes directly from the filesystem cache
     * to the target channel without actually copying them.  </p>
```
解释为：此方法可能比从该通道读取数据并将数据写入目标通道的简单循环更有效。<font
color="red">许多操作系统可以直接将字节从文件系统缓存传输到目标通道，而不必实际复制它们。</font>

源码里已经特别说明了，零拷贝依赖于操作系统，是的，如果底层网络接口卡支持收集操作的话，就可以进一步的优化。
在 Linux 内核
2.4及后期版本中，针对socket缓冲区描述符做了相应调整，DMA自带了收集功能，对于用户方面，用法还是一样，只是内部操作已经发生了改变，
原理交互变更如下：
![](/assets/images/2019/zerocopy/zero-sendfile-gather1.png)

具体过程：  
1、transferTo() 方法使用 DMA 将文件内容拷贝到内核读取缓冲区。

2、避免了内容的整体拷贝，只把包含数据位置和长度信息的描述符追加到socket缓冲区，DMA
引擎直接把数据从内核缓冲区传到协议引擎，从而消除了最后一次
CPU参与的拷贝动作，达到真正意义的零拷贝。



![](/assets/images/2019/zerocopy/zero-sendfile-gather2.png)

基于 sendfile + DMA gather copy 系统调用的零拷贝方式，整个拷贝过程会发生 2 次上下文切换、0 次 CPU 拷贝以及 2 次 DMA 拷贝，用户程序读写数据的流程如下：

1. 用户进程通过 sendfile() 函数向内核（kernel）发起系统调用，上下文从用户态（user space）切换为内核态（kernel space）。
2. CPU 利用 DMA 控制器将数据从主存或硬盘拷贝到内核空间（kernel space）的读缓冲区（read buffer）。
3. CPU 把读缓冲区（read buffer）的文件描述符（file descriptor）和数据长度拷贝到网络缓冲区（socket buffer）。
4. 基于已拷贝的文件描述符（file descriptor）和数据长度，CPU 利用 DMA 控制器的 gather/scatter 操作直接批量地将数据从内核的读缓冲区（read buffer）拷贝到网卡进行数据传输。
5. 上下文从内核态（kernel space）切换回用户态（user space），sendfile 系统调用执行返回。

sendfile + DMA gather copy 拷贝方式同样存在用户程序不能对数据进行修改的问题，而且本身需要硬件的支持，它只适用于将数据从文件拷贝到 socket 套接字上的传输过程。


# Linux零拷贝对比
无论是传统 I/O 拷贝方式还是引入零拷贝的方式，2 次 DMA Copy 是都少不了的，因为两次 DMA 都是依赖硬件完成的。下面从 CPU 拷贝次数、DMA 拷贝次数以及系统调用几个方面总结一下上述几种 I/O 拷贝方式的差别。

| 拷贝方式  |  cpu拷贝 | DMA拷贝  | 系统调用  |上下文切花 |
|---       |---       |---      |---       |---|
| 传统方式（read + write）  | 2|2| read/write|4 |
| 传统方式（read + write）  |1| 2| mmap/write|4 |
|  传统方式（read + write） |1|2|sendfile|2|
|sendfile + DMA gather copy   |0|2|sendfile|2|
|splice|0|2|splice|2|



# Netty零拷贝
Netty 中的零拷贝和上面提到的操作系统层面上的零拷贝不太一样, 我们所说的 Netty 零拷贝完全是基于（Java 层面）用户态的，它的更多的是偏向于数据操作优化这样的概念，具体表现在以下几个方面：

1. Netty 通过 DefaultFileRegion 类对 java.nio.channels.FileChannel 的 tranferTo() 方法进行包装，在文件传输时可以将文件缓冲区的数据直接发送到目的通道（Channel）
2. ByteBuf 可以通过 wrap 操作把字节数组、ByteBuf、ByteBuffer 包装成一个 ByteBuf 对象, 进而避免了拷贝操作
3. ByteBuf 支持 slice 操作, 因此可以将 ByteBuf 分解为多个共享同一个存储区域的 ByteBuf，避免了内存的拷贝
4. Netty 提供了 CompositeByteBuf 类，它可以将多个 ByteBuf 合并为一个逻辑上的 ByteBuf，避免了各个 ByteBuf 之间的拷贝

其中第 1 条属于操作系统层面的零拷贝操作，后面 3 条只能算用户层面的数据操作优化。

# RocketMQ和Kafka对比
RocketMQ 选择了 mmap + write
这种零拷贝方式，适用于业务级消息这种小块文件的数据持久化和传输；而 Kafka 采用的是
sendfile
这种零拷贝方式，适用于系统日志消息这种高吞吐量的大块文件的数据持久化和传输。但是值得注意的一点是，Kafka
的索引文件使用的是 mmap + write 方式，数据文件使用的是 sendfile 方式。

|消息队列 | 零拷贝方式|优点|缺点|
|---| ---| ---|---|
| Rocketmq |mmap + write | 适用于小块文件传输，频繁调用时，效率很高|不能很好的利用 DMA 方式，会比 sendfile 多消耗 CPU，内存安全性控制复杂，需要避免 JVM Crash 问题 |
| Kafka | sendfile| 可以利用 DMA 方式，消耗 CPU 较少，大块文件传输效率高，无内存安全性问题| 小块文件效率低于 mmap 方式，只能是 BIO 方式传输，不能使用 NIO 方式 |



参考资料：  
https://netty.io/  
https://juejin.im/post/5d84bd1f6fb9a06b2d780df7






       